{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "#referring to chapter six Data Analysis with Python and PySpark for guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().master('local[1]').appName(\"text\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike CSV data, JSON data doesnâ€™t need to worry about record delimiters or inferring data types (JSON forces the usage of string delimiters, so the value 03843 is a number, where \"03843\" is a string) - chapt 6 Data analysis with PySpark, Manning\n",
    "data = spark.read.json('../data/batch.json', multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  count was 17 when multiLine = False, when false, Json treated in regular dataFrame format\n",
    "# when interacting with pySpark, may be better to put new entries within single lines\n",
    "#eg: {id: 1, article: python, date: 2022}\n",
    "#    {id: 2, article: pyspark, date: 2022}\n",
    "# this allows us to operate on it like it were a csv file - worth considering\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: long (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- date_published: long (nullable = true)\n",
      " |-- dek: string (nullable = true)\n",
      " |-- direction: string (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- excerpt: string (nullable = true)\n",
      " |-- keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- lead_image_url: string (nullable = true)\n",
      " |-- next_page_url: string (nullable = true)\n",
      " |-- rendered_pages: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- total_pages: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- word_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inferred schema is pretty good, even the array within the keywords section is maintained appropriately\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'author', 'content', 'date_published', 'dek', 'direction', 'domain', 'excerpt', 'keywords', 'lead_image_url', 'next_page_url', 'rendered_pages', 'title', 'total_pages', 'url', 'word_count']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------+----+---------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+--------------------+-----------+--------------------+----------+\n",
      "|_id|              author|             content|date_published| dek|direction|              domain|             excerpt|            keywords|      lead_image_url|next_page_url|rendered_pages|               title|total_pages|                 url|word_count|\n",
      "+---+--------------------+--------------------+--------------+----+---------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+--------------------+-----------+--------------------+----------+\n",
      "|  1|          Matt Makai|\\nAmazon Web Serv...|          2021|null|      ltr|     fullstackpython|Learn how to use ...|    [python, lambda]|https://www.fulls...|         null|             1|Application Perfo...|          1|https://www.fulls...|      1113|\n",
      "|  2|     Ronnie Atuhaire|Hey there ðŸ‘‹, wel...|          2022|null|      ltr|  blog.octachart.com|Hey there ðŸ‘‹, wel...|  [python, scraping]|https://hashnode....|         null|             1|Asynchronous Web ...|          1|https://blog.octa...|       671|\n",
      "|  3|           Not found|In this tutorial,...|          2022|null|      ltr|www.blog.pythonli...|In this tutorial,...|  [python, openPyxl]|                null|         null|             1|Automating Excel ...|          1|https://www.blog....|        67|\n",
      "|  4|               Chris|\\nThis article co...|          2020|null|      ltr|    blog.finxter.com|This article comp...|[python, machine ...|https://blog.finx...|         null|             1|Best 15+ Machine ...|          1|https://blog.finx...|      2907|\n",
      "|  5|                null|Soham Sarkar\\n\\n\\...|          2021|null|      ltr|            hashnode|Hello People, In ...|[python, escape s...|https://hashnode....|         null|             1|Getting started w...|          1|https://sohoxic.h...|         2|\n",
      "|  6|        Soham Sarkar|The tech world co...|          2022|null|      ltr|            hashnode|The tech world co...|     [python, learn]|https://hashnode....|         null|             1|How I Learned to ...|          1|https://boadzie.h...|       937|\n",
      "|  7|          Matt Makai|\\nAmazon Web Serv...|          2021|null|      ltr|     fullstackpython|Learn how to moni...|    [python, lambda]|https://www.fulls...|         null|             1|How to Monitor Py...|          1|https://www.fulls...|      1445|\n",
      "|  8|       Sourav Mandal|Sourav MandalYour...|          2022|null|      ltr|            hashnode|Hey There, I am S...|[python, web deve...|https://hashnode....|         null|             1|How To Start Your...|          1|https://souravwd....|         2|\n",
      "|  9|Muhammad Hammad Asif|Python is an open...|          2022|null|      ltr|            hashnode|Getting Started w...|            [python]|https://hashnode....|         null|             1| Python For Everyone|          1|https://hami.hash...|       218|\n",
      "| 10|          Rahul Soni|Hello there, in t...|          2022|null|      ltr|            hashnode|Make RESTFul API ...|      [python, CRUD]|https://hashnode....|         null|             1|Quick Guide to ma...|          1|https://r4hu1s0n7...|       665|\n",
      "| 11|          Matt Makai|\\nRecording phone...|          2021|null|      ltr|     fullstackpython|Use Python, Djang...|     [python, Voice]|https://www.fulls...|         null|             1|Using Django & As...|          1|https://www.fulls...|      3783|\n",
      "| 12|            Israel W|Note: This articl...|          2022|null|      ltr|            hashnode|How to write less...|   [python, concise]|https://hashnode....|         null|             1|Writing more conc...|          1|https://codewithi...|       320|\n",
      "+---+--------------------+--------------------+--------------+----+---------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+--------------------+-----------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "|_id|     wordsonline|\n",
      "+---+----------------+\n",
      "|  1|          python|\n",
      "|  1|          lambda|\n",
      "|  2|          python|\n",
      "|  2|        scraping|\n",
      "|  3|          python|\n",
      "|  3|        openPyxl|\n",
      "|  4|          python|\n",
      "|  4|machine learning|\n",
      "|  5|          python|\n",
      "|  5| escape sequence|\n",
      "|  6|          python|\n",
      "|  6|           learn|\n",
      "|  7|          python|\n",
      "|  7|          lambda|\n",
      "|  8|          python|\n",
      "|  8|   web developer|\n",
      "|  9|          python|\n",
      "| 10|          python|\n",
      "| 10|            CRUD|\n",
      "| 11|          python|\n",
      "+---+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explode out the keywords\n",
    "data2 = data.select(\"_id\", explode(\"keywords\").alias(\"wordsonline\"))\n",
    "data2.show()\n",
    "# pyspark allows for greater control over data processing than in pandas, here I can operate on the exploded lists given their keywords in a simpler cleaner fashion than with pandas (see proof_of_concept.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "842fbf2151771c5fab737f7e91cae4a6b3fd587e0ef9c8eecff0f9eb53e93c36"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
