{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Can use SparkNLP for this too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import SentenceDetector, Tokenizer, LemmatizerModel, SentimentDetectorModel\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, FloatType\n",
    "\n",
    "# Initialize SparkNLP\n",
    "spark = sparknlp.start()\n",
    "\n",
    "# Load pre-trained models\n",
    "document_assembler = DocumentAssembler().setInputCol(\"article_content\").setOutputCol(\"document\")\n",
    "sentence_detector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentences\")\n",
    "tokenizer = Tokenizer().setInputCols([\"sentences\"]).setOutputCol(\"tokens\")\n",
    "lemmatizer = LemmatizerModel.pretrained().setInputCols([\"tokens\"]).setOutputCol(\"lemmas\")\n",
    "sentiment_detector = SentimentDetectorModel.pretrained().setInputCols([\"lemmas\"]).setOutputCol(\"sentiment\")\n",
    "\n",
    "# Define UDF to get overall sentiment score\n",
    "def get_sentiment_score(sentiment):\n",
    "    return sentiment['result']\n",
    "\n",
    "get_sentiment_score_udf = udf(get_sentiment_score, FloatType())\n",
    "\n",
    "# Define UDF to get overall sentiment category\n",
    "def get_sentiment_category(sentiment):\n",
    "    return sentiment['sentiment']\n",
    "\n",
    "get_sentiment_category_udf = udf(get_sentiment_category, StringType())\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, lemmatizer, sentiment_detector])\n",
    "\n",
    "# Apply pipeline to input DataFrame\n",
    "output = pipeline.fit(input_df).transform(input_df)\n",
    "\n",
    "# Extract sentiment information from output\n",
    "output = output.selectExpr(\"article_content\", \"explode(sentiment.result) as sentiment_info\")\n",
    "\n",
    "# Add columns for sentiment score and category\n",
    "output = output.withColumn(\"sentiment_score\", get_sentiment_score_udf(\"sentiment_info\"))\n",
    "output = output.withColumn(\"sentiment_category\", get_sentiment_category_udf(\"sentiment_info\"))\n",
    "\n",
    "# Show output DataFrame\n",
    "output.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we start by initializing SparkNLP and loading the necessary pre-trained models for document assembly, sentence detection, tokenization, lemmatization, and sentiment detection.\n",
    "\n",
    "We then define two UDFs to extract the overall sentiment score and category from the sentiment output of the SentimentDetectorModel.\n",
    "\n",
    "Next, we define a pipeline consisting of the pre-trained models and apply it to the input DataFrame to generate an output DataFrame with sentiment information.\n",
    "\n",
    "Finally, we use the UDFs to add columns for the sentiment score and category to the output DataFrame.\n",
    "\n",
    "Note that in this example, we assume that the SentimentDetectorModel will provide sentiment information at the sentence level. If you want to get the overall sentiment of the entire article, you may need to aggregate the sentiment information across all sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "+--------------------------------------------------------------------------------------------+---------------+---------------+------------------+\n",
    "|article_content                                                                             |sentiment_info |sentiment_score|sentiment_category|\n",
    "+--------------------------------------------------------------------------------------------+---------------+---------------+------------------+\n",
    "|Asynchronous Web Scraping With Python AIOHTTP                                           |[positive, 1.0]|1.0            |positive          |\n",
    "|Asynchronous Web Scraping With Python AIOHTTP                                           |[positive, 1.0]|1.0            |positive          |\n",
    "|Automating Excel with Python Video Overview - Mouse Vs Python                           |[positive, 1.0]|1.0            |positive          |\n",
    "|How to Monitor Python Functions on AWS Lambda with Sentry                                |[positive, 0.5]|0.5            |positive          |\n",
    "|How to Monitor Python Functions on AWS Lambda with Sentry                                |[positive, 0.5]|0.5            |positive          |\n",
    "|How to Monitor Python Functions on AWS Lambda with Sentry                                |[negative, 0.5]|0.5            |negative          |\n",
    "+--------------------------------------------------------------------------------------------+---------------+---------------+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
