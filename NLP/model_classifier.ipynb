{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.13k/1.13k [00:00<00:00, 128kB/s]\n",
      "Downloading: 100%|██████████| 1.52G/1.52G [04:56<00:00, 5.49MB/s]\n",
      "Downloading: 100%|██████████| 26.0/26.0 [00:00<00:00, 4.34kB/s]\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 2.49MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 1.73MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 3.01MB/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# check here for further docs https://huggingface.co/facebook/bart-large-mnli\n",
    "# Model predeccesor papers: https://arxiv.org/abs/1909.00161 Benchmarking zero-shot text classification, Datasets, Evaluation and Entailment approach\n",
    "# Models paper itself: https://arxiv.org/abs/1910.13461 BART: Denoising Sequence-to-sequence pre-training for natural language generation, translation and comprehension\n",
    "# BART here is trained on the MNLI corpus of sentence label pairs: https://cims.nyu.edu/~sbowman/multinli/?ref=blog.paperspace.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"cooking\", \"working\", \"sleeping\", \"programming\"]\n",
    "hypothesis_template = 'This text is about {}.'\n",
    "sequence = \"When I program, the code is compiled down to assembly, and then down to binary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `multi_class` argument has been deprecated and renamed to `multi_label`. `multi_class` will be removed in a future version of Transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'When I program, the code is compiled down to assembly, and then down to binary.', 'labels': ['programming', 'working', 'sleeping', 'cooking'], 'scores': [0.9569053053855896, 0.7005553841590881, 0.0004397584416437894, 0.0004357791331131011]}\n"
     ]
    }
   ],
   "source": [
    "prediction = classifier(sequence, labels, hypothesis_template=hypothesis_template, multi_class=True)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model works pretty well, and we can certainly use it in the project. It will be helpful to know the specificity of the labels, however..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"programming\",\n",
    "    \"python\",\n",
    "    \"java\",\n",
    "    \"high performance teams\",\n",
    "    \"stock market\",\n",
    "    \"sleeping\",\n",
    "    \"eating\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_template = \"This text is about {}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"A team needs to be properly looked after, and everyone's input needs to be taken into account to work effectively.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `multi_class` argument has been deprecated and renamed to `multi_label`. `multi_class` will be removed in a future version of Transformers.\n"
     ]
    }
   ],
   "source": [
    "prediction = classifier(sequence, labels, hypothesis_template=hypothesis_template, multi_class=True)\n",
    "\n",
    "# returns dict\n",
    "# sequence str- the sentence\n",
    "# labels list[str] list of labels sorted by likelihood\n",
    "# scores list[float] list of probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: high performance teams, 0.2316187620162964\n",
      "Label: programming, 0.17947016656398773\n",
      "Label: java, 0.050939228385686874\n",
      "Label: python, 0.025592995807528496\n",
      "Label: stock market, 0.01506301760673523\n",
      "Label: eating, 0.00031525595113635063\n",
      "Label: sleeping, 0.00016555377806071192\n"
     ]
    }
   ],
   "source": [
    "labels = prediction['labels']\n",
    "scores = prediction['scores']\n",
    "\n",
    "for label, score in zip(labels, scores):\n",
    "    print(f\"Label: {label}, {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"Amazon Web Services (AWS) Lambda is a usage-based\\ncomputing infrastructure service that can execute\\nPython 3 code. One of the challenges of this\\nenvironment is ensuring efficient performance of your Lambda Functions.\\nApplication performance monitoring (APM) is particularly useful in these\\nsituations because you are billed based on how long you use the\\nresources.\\nIn this post we will install and configure\\nSentry's APM that works via a\\nLambda layer.\\nNote that if you are looking for error monitoring rather than performance\\nmonitoring, take a look at\\nHow to Monitor Python Functions on AWS Lambda with Sentry\\nrather than following this post.\\nFirst steps with AWS Lambda\\nA local development environment is not\\nrequired to follow this tutorial because all of the coding and configuration\\ncan happen in a web browser through the\\nAWS Console.\\nSign into your existing AWS account\\nor sign up for a new account. Lambda\\ngives you the first 1 million requests for free so that you can execute\\nbasic applications without no or low cost.\\n\\nWhen you log into your account, use the search box to enter\\n\\\"lambda\\\" and select \\\"Lambda\\\" when it appears to get to the right\\npage.\\n\\nIf you have already used Lambda before, you will see your existing Lambda\\nfunctions in a searchable table. We're going to create a new function so\\nclick the \\\"Create function\\\" button.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_without_newlines = article.replace(\"\\n\", \"\")\n",
    "prepped_article = text_without_newlines.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldict = {\n",
    "    \"programming\": [],\n",
    "    \"python\": [],\n",
    "    \"java\":[] ,\n",
    "    \"high performance teams\":[] ,\n",
    "    \"stock market\":[] ,\n",
    "    \"sleeping\": [],\n",
    "    \"eating\": []\n",
    "}\n",
    "\n",
    "for sentence in prepped_article:\n",
    "    try:\n",
    "        prediction = classifier(sentence, labels, hypothesis_template=hypothesis_template, multi_label=True)\n",
    "        for label, score in zip(prediction['labels'], prediction['scores']):\n",
    "            if label in labeldict:\n",
    "                labeldict[label].append(score)\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'programming': 0.6534916612912308, 'python': 0.23560783724215897, 'java': 0.019242797880327667, 'high performance teams': 0.058129258919507265, 'stock market': 0.0037784543078900738, 'sleeping': 0.0006328487771415067, 'eating': 0.0005542129345650954}\n"
     ]
    }
   ],
   "source": [
    "aggregated_scores = {}\n",
    "\n",
    "for label, scores in labeldict.items():\n",
    "    total_score = statistics.mean(scores)\n",
    "    aggregated_scores[label] = total_score\n",
    "\n",
    "print(aggregated_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "842fbf2151771c5fab737f7e91cae4a6b3fd587e0ef9c8eecff0f9eb53e93c36"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
