{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkNLP\n",
    "\n",
    "I've encountered some troubles with bringing in python objects like nltk and Language_tool when running spark jobs. A way around this could be using SparkNLP\n",
    "\n",
    "```\n",
    "py -m pip install spark-nlp\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "```\n",
    "^^ That above requests 4gb but we can experiment with lower memory\n",
    "\n",
    "## Spelling mistakes\n",
    "\n",
    "Below is an attempt to gather spelling mistakes, as that was the job that uses Language_tool and was giving me problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "# Create a sample dataframe\n",
    "data = [(\"This is a sampl text with spelling mistaks.\"), (\"It is hard to spel evrythng correctly.\"), (\"Let's see if SparkNLP can help us find the errors.\")]\n",
    "df = spark.createDataFrame(data, [\"text\"])\n",
    "\n",
    "# Define the pipeline\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = RegexTokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "spellChecker = NorvigSweetingApproach() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"spell_checked\") \\\n",
    "    .setDictionary(\"src/main/resources/spell/NorvigSweeting/big.txt\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"spell_checked\"]) \\\n",
    "    .setOutputCols([\"spell_checked\"]) \\\n",
    "    .setOutputAsArray(True)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    documentAssembler,\n",
    "    tokenizer,\n",
    "    spellChecker,\n",
    "    finisher\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the dataframe\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "# Apply the pipeline on the dataframe\n",
    "result = model.transform(df)\n",
    "\n",
    "# View the result\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flesch Readability\n",
    "The below also tackles the Flesch reading score, which has been inserted into the report job but I think it doesn't work correctly as of now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "# Create a sample dataframe\n",
    "data = [(\"This is a sample sentence.\",), (\"It contains some words and punctuation.\",), (\"Let's see what the Flesch score is.\"), (\"It should be around 70-80 for normal text.\")]\n",
    "df = spark.createDataFrame(data, [\"text\"])\n",
    "\n",
    "# Define the pipeline\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "posTagger = PerceptronModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"pos\")\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "    .setInputCols([\"token\", \"pos\"]) \\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"lemma\"]) \\\n",
    "    .setOutputCols([\"lemma\"]) \\\n",
    "    .setOutputAsArray(True)\n",
    "\n",
    "# Define a UDF to calculate the Flesch reading score\n",
    "def flesch_score(text):\n",
    "    num_sentences = text.count('.')\n",
    "    num_words = len(text.split())\n",
    "    num_syllables = 0\n",
    "    for word in text.split():\n",
    "        syllables = SyllableCountingModel.pretrained() \\\n",
    "            .setInputCols([\"token\"]) \\\n",
    "            .setOutputCol(\"syllables\") \\\n",
    "            .transform(spark.createDataFrame([(word,)]).toDF(\"text\")).collect()[0].syllables\n",
    "        num_syllables += syllables[0]\n",
    "    return 206.835 - 1.015 * (num_words / num_sentences) - 84.6 * (num_syllables / num_words)\n",
    "\n",
    "flesch_score_udf = udf(flesch_score, FloatType())\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    documentAssembler,\n",
    "    tokenizer,\n",
    "    posTagger,\n",
    "    lemmatizer,\n",
    "    finisher\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the dataframe\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "# Apply the pipeline on the dataframe\n",
    "result = model.transform(df)\n",
    "\n",
    "# Add the Flesch score column\n",
    "result = result.withColumn(\"flesch_score\", flesch_score_udf(result[\"lemma\"]))\n",
    "\n",
    "# View the result\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further ones to check out that may be useful:\n",
    "\n",
    " - DependencyParserModel - analyzes grammatical structure\n",
    " - ChunkerModel - groups related words in a sentence\n",
    " - SentenceDetectorDLModel - sentence boundary detection to split text into individual sentences, to prepare data for named entity recognition and sentiment analysis\n",
    " - NERDLModel - identify named entities\n",
    " - SentimentDLModel - sentiment analysis for sentences positive, negative or neutral\n",
    " - MultiClassifierDLModel - multi-class specification to classify text data into multiple categories, classifies text data into topics, genres, or other sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MultiClassifierDLModel\n",
    "\n",
    "Running a few examples in:\n",
    "```\n",
    "texts = [\n",
    "    'Asynchronous Web Scraping With Python AIOHTTP',\n",
    "    'Automating Excel with Python Video Overview - Mouse Vs Python',\n",
    "    'How to Monitor Python Functions on AWS Lambda with Sentry'\n",
    "]\n",
    "```\n",
    "\n",
    "has produced the following:\n",
    "\n",
    "```\n",
    "+---+-----------------------------------------+\n",
    "|id |result                                   |\n",
    "+---+-----------------------------------------+\n",
    "|0  |[[chunk, 0, 5, PRODUCT], [chunk, 7, 21, TECHNOLOGY]]|\n",
    "|1  |[[chunk, 0, 8, PRODUCT], [chunk, 18, 25, TECHNOLOGY], [chunk, 35, 42, PERSON]]|\n",
    "|2  |[[chunk, 13, 18, PRODUCT], [chunk, 28, 32, TECHNOLOGY], [chunk, 42, 53, ORGANIZATION]]|\n",
    "+---+-----------------------------------------+\n",
    "\n",
    "```\n",
    "\n",
    "Could be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Unfortunately, there is no pre-trained model in SparkNLP that can specifically analyze the reputation of a blog article. However, there are some NLP techniques that can be used to approach this problem.\n",
    "\n",
    "For example, you could use a pre-trained named entity recognition (NER) model to identify entities such as organizations, people, and locations in the text. This could help you determine if the article is discussing reputable companies or individuals in the field of software engineering.\n",
    "\n",
    "Additionally, you could use a pre-trained sentiment analysis model to determine the overall sentiment of the article, which could provide some insight into whether the article is positive or negative towards the topic.\n",
    "\n",
    "Finally, you could also use pre-trained models for topic classification to identify the main topics discussed in the article. This could help you determine if the article is discussing relevant and current topics in the field of software engineering.\n",
    "\n",
    "While these techniques do not directly address the reputation of the author or the website, they can still provide some useful information for evaluating the credibility of a blog article in the field of software engineering.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
