{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site reputation\n",
    "\n",
    "I've been struggling to get a nice method of doing this, and I bet there's more to do, but so far we can create a list of sites that are reputable and use them to judge credbility.\n",
    "\n",
    "If something is posted on a reputable website then it can be considered credible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "import tldextract\n",
    "\n",
    "# create a set of reputable websites\n",
    "reputable_websites = {'apple.com', 'shopify.com', 'science.org', 'ieee.org', 'news.ycombinator.com'}\n",
    "\n",
    "# define a function to check if a website is reputable\n",
    "def is_reputable(url):\n",
    "    domain = tldextract.extract(url).registered_domain\n",
    "    return domain in reputable_websites\n",
    "\n",
    "# register the function as a UDF\n",
    "is_reputable_udf = udf(is_reputable, BooleanType())\n",
    "\n",
    "# read in the parquet file\n",
    "df = spark.read.parquet('path/to/articles.parquet')\n",
    "\n",
    "# add a column indicating if the website is reputable or not\n",
    "df = df.withColumn('is_reputable', is_reputable_udf('url'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for instance the above uses a list of websites which we can define somewhere. \n",
    "\n",
    "Say take a list from somewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
